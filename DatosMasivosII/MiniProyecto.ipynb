{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniProyecto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPXWUGi0Hb4jNOF/4KB9wM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanMartignon/DatosMasivosII/blob/main/MiniProyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJu2_5z2uZlc"
      },
      "source": [
        "# Martiñón Luna Jonathan josé\n",
        "## Octubre 7, 2020\n",
        "## Datos Masivos II\n",
        "## Licenciatura en Ciencia de Datos.\n",
        "\n",
        "----\n",
        "**Instrucciones**\n",
        "\n",
        "- El objetivo de este mini-proyecto es identificar los tópicos a partir de un conjunto de comentarios usando el método de SVD.\n",
        "\n",
        "- La base de datos a usar es: https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews\n",
        "\n",
        "- La columna a usar es: Review Text\n",
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBT27Sk2PK8K",
        "outputId": "e166a92b-2896-4ba8-9889-4721c87b0176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "#Me pedía descargar las stopwords.\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDLAYqAguXJw"
      },
      "source": [
        "# Importamos las librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDNSZMKCB9mS",
        "outputId": "2ba6cb08-6898-4bf5-8c90-aa62f6c1d93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Leemos el csv\n",
        "data = pd.read_csv(\"/content/Womens.csv\")\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
              "0           0          767   33  ...       Initmates        Intimate   Intimates\n",
              "1           1         1080   34  ...         General         Dresses     Dresses\n",
              "2           2         1077   60  ...         General         Dresses     Dresses\n",
              "3           3         1049   50  ...  General Petite         Bottoms       Pants\n",
              "4           4          847   47  ...         General            Tops     Blouses\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UuKvP7BB93K",
        "outputId": "5705ca5e-1e74-422c-a7d4-6cc308f22d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Extraemos los \"documentos\" con los que trabajaremos\n",
        "documentos = list(data[\"Review Text\"])\n",
        "print(f\"Contamos con {len(documentos)} comentarios (Documentos)\\n\")\n",
        "documentos[0:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contamos con 23486 comentarios (Documentos)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Absolutely wonderful - silky and sexy and comfortable',\n",
              " 'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.',\n",
              " 'I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3xfL6EjILRw"
      },
      "source": [
        "--- \n",
        "\n",
        "Para el ejemplo de clase se hizo notar que las noticias pertenecían a 20 grupos diferentes. En este caso tomaremos las diferentes clases para los comentarios. \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjqIaE-HB-C1",
        "outputId": "ae0d05f7-9bab-47e4-8b43-90a17adf0c9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Contamos con {len(data['Class Name'].unique())} clases diferentes\\n\")\n",
        "data['Class Name'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contamos con 21 clases diferentes\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Intimates', 'Dresses', 'Pants', 'Blouses', 'Knits', 'Outerwear',\n",
              "       'Lounge', 'Sweaters', 'Skirts', 'Fine gauge', 'Sleep', 'Jackets',\n",
              "       'Swim', 'Trend', 'Jeans', 'Legwear', 'Shorts', 'Layering',\n",
              "       'Casual bottoms', nan, 'Chemises'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XBQBo-_JV7U"
      },
      "source": [
        "---\n",
        "\n",
        "# Preprocesamiento\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxXaDJH3NHgK"
      },
      "source": [
        "#Convertimos nuestra lista a Dataframe\n",
        "pre_data = pd.DataFrame({'document':documentos})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLbuw2_hMJgi",
        "outputId": "ea5eef4f-79b5-49d5-cec7-7db72241d5fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Encontramos datos nulos\n",
        "nulos = pre_data[\"document\"].isnull().sum()\n",
        "print(f\"Contamos con {nulos} valores nulos\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contamos con 845 valores nulos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOrLGBYQNmms"
      },
      "source": [
        "# Eliminamos los valores nulos y reseteamos el índice\n",
        "pre_data.dropna(inplace=True)\n",
        "pre_data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sRrXbkiN4Y_",
        "outputId": "807f601f-cc0d-4065-eea4-978cf8d20f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Verificamos ausencia de  datos nulos\n",
        "nulos = pre_data[\"document\"].isnull().sum()\n",
        "print(f\"Contamos con {nulos} valores nulos\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contamos con 0 valores nulos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ5tj-VdB-KQ"
      },
      "source": [
        "# Limpiamos el dataset\n",
        "pre_data['clean_doc'] = pre_data['document'].str.replace(\"[^a-zA-Z#]\", \" \")#se remueve signos, caracteres especiales..\n",
        "pre_data['clean_doc'] = pre_data['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3])) #se remueve palabras cortas (long menor a 3)\n",
        "pre_data['clean_doc'] = pre_data['clean_doc'].apply(lambda x: x.lower()) #se convierte el texto a minúsculas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L-ErJeuO4eV",
        "outputId": "00f7bdbf-0bed-4d73-8fb0-d1bae8fb2bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "pre_data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>clean_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>absolutely wonderful silky sexy comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>love this dress sooo pretty happened find stor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>such high hopes this dress really wanted work ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document                                          clean_doc\n",
              "0  Absolutely wonderful - silky and sexy and comf...        absolutely wonderful silky sexy comfortable\n",
              "1  Love this dress!  it's sooo pretty.  i happene...  love this dress sooo pretty happened find stor...\n",
              "2  I had such high hopes for this dress and reall...  such high hopes this dress really wanted work ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt88eE01B-Jc"
      },
      "source": [
        "# Eliminando stop words y tokenizando\n",
        "\n",
        "stop_words = stopwords.words('english') # Cargamos las stop words\n",
        "\n",
        "tokenized_doc = pre_data['clean_doc'].apply(lambda x: x.split()) #tokenización\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words]) #eliminación de stop-words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRlzJXp4B99L",
        "outputId": "ddd3aabd-1536-46e9-b6db-0b73d6a53f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [absolutely, wonderful, silky, sexy, comfortable]\n",
              "1        [love, dress, sooo, pretty, happened, find, st...\n",
              "2        [high, hopes, dress, really, wanted, work, ini...\n",
              "3        [love, love, love, jumpsuit, flirty, fabulous,...\n",
              "4        [shirt, flattering, adjustable, front, perfect...\n",
              "                               ...                        \n",
              "22636    [happy, snag, dress, great, price, easy, slip,...\n",
              "22637    [reminds, maternity, clothes, soft, stretchy, ...\n",
              "22638    [well, never, would, worked, glad, able, store...\n",
              "22639    [bought, dress, wedding, summer, cute, unfortu...\n",
              "22640    [dress, lovely, platinum, feminine, fits, perf...\n",
              "Name: clean_doc, Length: 22641, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa1GqVlPB98Y"
      },
      "source": [
        "detokenized_doc = [] # volvemos a unir lo que quedó\n",
        "\n",
        "for i in range(len(pre_data)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "    \n",
        "pre_data['clean_doc'] = detokenized_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9ANUXz_B9r9",
        "outputId": "a655be99-5dbf-4c0a-f96b-98e74e85e18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pre_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>clean_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>absolutely wonderful silky sexy comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>love dress sooo pretty happened find store gla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>high hopes dress really wanted work initially ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>love love love jumpsuit flirty fabulous every ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>shirt flattering adjustable front perfect leng...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document                                          clean_doc\n",
              "0  Absolutely wonderful - silky and sexy and comf...        absolutely wonderful silky sexy comfortable\n",
              "1  Love this dress!  it's sooo pretty.  i happene...  love dress sooo pretty happened find store gla...\n",
              "2  I had such high hopes for this dress and reall...  high hopes dress really wanted work initially ...\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...  love love love jumpsuit flirty fabulous every ...\n",
              "4  This shirt is very flattering to all due to th...  shirt flattering adjustable front perfect leng..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU7iIadLRXGH"
      },
      "source": [
        "---\n",
        "Creando la matriz de términos\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gq_-eN-B9rJ",
        "outputId": "8d7e036f-1a66-41e5-d720-432e7680e69a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Usamos TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "                            max_features= 1000, # máximo número de términos\n",
        "                            max_df = 0.5, \n",
        "                            smooth_idf=True)\n",
        "X = vectorizer.fit_transform(pre_data['clean_doc'])\n",
        "print(\"Tamaño de la matriz T-D: \", X.shape) # visualizamos el tamaño de la matriz\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño de la matriz T-D:  (22641, 1000)\n",
            "  (0, 150)\t0.26908313656134575\n",
            "  (0, 714)\t0.5029911966336686\n",
            "  (0, 741)\t0.54868250035246\n",
            "  (0, 978)\t0.4745023713096423\n",
            "  (0, 1)\t0.3852131035619599\n",
            "  (1, 895)\t0.28310425687868823\n",
            "  (1, 495)\t0.3282385862459109\n",
            "  (1, 894)\t0.1735493428036656\n",
            "  (1, 199)\t0.18613776111958308\n",
            "  (1, 420)\t0.23728076471436937\n",
            "  (1, 458)\t0.1406400619673494\n",
            "  (1, 367)\t0.23917659146304146\n",
            "  (1, 443)\t0.15549783676623677\n",
            "  (1, 76)\t0.15054782797842423\n",
            "  (1, 587)\t0.5019192913125554\n",
            "  (1, 542)\t0.17891065485646476\n",
            "  (1, 551)\t0.1380808236247941\n",
            "  (1, 326)\t0.2220438270605945\n",
            "  (1, 797)\t0.16807613348792108\n",
            "  (1, 347)\t0.32610477784015773\n",
            "  (1, 624)\t0.16351508888444327\n",
            "  (1, 226)\t0.11109325804703755\n",
            "  (1, 473)\t0.203073219042927\n",
            "  (2, 999)\t0.18478399575763998\n",
            "  (2, 713)\t0.21047708055845665\n",
            "  :\t:\n",
            "  (22639, 988)\t0.22882316313572645\n",
            "  (22639, 277)\t0.22150294249301758\n",
            "  (22639, 187)\t0.15359419245570932\n",
            "  (22639, 465)\t0.2017099583125508\n",
            "  (22639, 932)\t0.17142127973800325\n",
            "  (22639, 285)\t0.15560221725677245\n",
            "  (22639, 584)\t0.18883446942830953\n",
            "  (22639, 94)\t0.211700194386792\n",
            "  (22639, 448)\t0.11726039059625402\n",
            "  (22639, 461)\t0.16522645656030285\n",
            "  (22639, 582)\t0.1442616335935548\n",
            "  (22639, 491)\t0.17294132610364563\n",
            "  (22639, 941)\t0.20405018407179956\n",
            "  (22639, 76)\t0.15597280437246597\n",
            "  (22639, 226)\t0.23019298567301505\n",
            "  (22640, 365)\t0.3996949651504784\n",
            "  (22640, 234)\t0.358413121227397\n",
            "  (22640, 659)\t0.32890058213294476\n",
            "  (22640, 475)\t0.3281133013521104\n",
            "  (22640, 152)\t0.34343503718711343\n",
            "  (22640, 285)\t0.2505082667906759\n",
            "  (22640, 584)\t0.30400977878587265\n",
            "  (22640, 278)\t0.3889557940628573\n",
            "  (22640, 952)\t0.1928846560360797\n",
            "  (22640, 226)\t0.18529699282227952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgRhmFIKSkVM"
      },
      "source": [
        "---\n",
        "Calculando la descomposición de valores singulares.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S35kP7-B8jW",
        "outputId": "bb819e84-be86-4d5d-92c1-e5a4cb2bc732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Usamos la función \"TruncatedSVD\"\n",
        "\n",
        "#Creamos el modelo\n",
        "svd_model = TruncatedSVD(n_components=21, \n",
        "                        algorithm='randomized', \n",
        "                         n_iter=100, \n",
        "                         random_state=122)\n",
        "\n",
        "svd_model.fit(X) #Entrenamos\n",
        "len(svd_model.components_) #Mostramos la cantidad de componentes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzD6nNUhTSBO"
      },
      "source": [
        "---\n",
        "\n",
        "Obteniendo los tópicos\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw1fo7YrB8HG",
        "outputId": "8d7d4811-eea9-4b96-9811-a13e103133dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Obtenemos los tópicos a partir de los componentes del modelo\n",
        "terms = vectorizer.get_feature_names()\n",
        "terms[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['able',\n",
              " 'absolutely',\n",
              " 'actual',\n",
              " 'actually',\n",
              " 'added',\n",
              " 'addition',\n",
              " 'adds',\n",
              " 'adjustable',\n",
              " 'adorable',\n",
              " 'adore']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEv6VwmBB8A5",
        "outputId": "bf1c257e-cd92-4278-c772-b24b79289182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Visualizamos algunas de las plabras más importantes en cada uno de los tópicos\n",
        "for i, comp in enumerate(svd_model.components_):\n",
        "    terms_comp = zip(terms, comp)\n",
        "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
        "    print(\"Topic \"+str(i)+\":\")\n",
        "    for t in sorted_terms:\n",
        "        print(t[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "dress\n",
            "love\n",
            "size\n",
            "great\n",
            "like\n",
            "wear\n",
            "small\n",
            "Topic 1:\n",
            "dress\n",
            "beautiful\n",
            "slip\n",
            "dresses\n",
            "wedding\n",
            "bust\n",
            "belt\n",
            "Topic 2:\n",
            "love\n",
            "great\n",
            "comfortable\n",
            "jeans\n",
            "dress\n",
            "soft\n",
            "perfect\n",
            "Topic 3:\n",
            "size\n",
            "love\n",
            "small\n",
            "great\n",
            "true\n",
            "wear\n",
            "perfect\n",
            "Topic 4:\n",
            "shirt\n",
            "cute\n",
            "small\n",
            "dress\n",
            "super\n",
            "runs\n",
            "comfortable\n",
            "Topic 5:\n",
            "great\n",
            "jeans\n",
            "pants\n",
            "looks\n",
            "size\n",
            "cute\n",
            "skirt\n",
            "Topic 6:\n",
            "sweater\n",
            "great\n",
            "small\n",
            "medium\n",
            "large\n",
            "wear\n",
            "looks\n",
            "Topic 7:\n",
            "great\n",
            "size\n",
            "beautiful\n",
            "shirt\n",
            "color\n",
            "true\n",
            "fits\n",
            "Topic 8:\n",
            "sweater\n",
            "size\n",
            "cute\n",
            "true\n",
            "soft\n",
            "comfortable\n",
            "super\n",
            "Topic 9:\n",
            "cute\n",
            "love\n",
            "super\n",
            "really\n",
            "runs\n",
            "like\n",
            "look\n",
            "Topic 10:\n",
            "comfortable\n",
            "fabric\n",
            "skirt\n",
            "soft\n",
            "nice\n",
            "wear\n",
            "flattering\n",
            "Topic 11:\n",
            "length\n",
            "skirt\n",
            "perfect\n",
            "petite\n",
            "short\n",
            "little\n",
            "long\n",
            "Topic 12:\n",
            "skirt\n",
            "wear\n",
            "sweater\n",
            "fits\n",
            "waist\n",
            "jeans\n",
            "size\n",
            "Topic 13:\n",
            "cute\n",
            "skirt\n",
            "color\n",
            "store\n",
            "beautiful\n",
            "online\n",
            "tried\n",
            "Topic 14:\n",
            "large\n",
            "pants\n",
            "runs\n",
            "jeans\n",
            "nice\n",
            "sweater\n",
            "beautiful\n",
            "Topic 15:\n",
            "comfortable\n",
            "sweater\n",
            "flattering\n",
            "skirt\n",
            "shirt\n",
            "soft\n",
            "petite\n",
            "Topic 16:\n",
            "jeans\n",
            "beautiful\n",
            "color\n",
            "small\n",
            "perfect\n",
            "looks\n",
            "ordered\n",
            "Topic 17:\n",
            "perfect\n",
            "colors\n",
            "pants\n",
            "quality\n",
            "look\n",
            "price\n",
            "sale\n",
            "Topic 18:\n",
            "pants\n",
            "little\n",
            "color\n",
            "comfortable\n",
            "like\n",
            "material\n",
            "beautiful\n",
            "Topic 19:\n",
            "beautiful\n",
            "fits\n",
            "quality\n",
            "cute\n",
            "small\n",
            "jeans\n",
            "really\n",
            "Topic 20:\n",
            "material\n",
            "nice\n",
            "really\n",
            "jeans\n",
            "quality\n",
            "good\n",
            "pretty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xprBR3fqUUb2"
      },
      "source": [
        "# Duda\n",
        "¿Cada tópico corresponde en ese orden a una clase?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLLuze7nB7_G",
        "outputId": "3a868432-236a-40a8-bf96-b1b8af265ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data['Class Name'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Intimates', 'Dresses', 'Pants', 'Blouses', 'Knits', 'Outerwear',\n",
              "       'Lounge', 'Sweaters', 'Skirts', 'Fine gauge', 'Sleep', 'Jackets',\n",
              "       'Swim', 'Trend', 'Jeans', 'Legwear', 'Shorts', 'Layering',\n",
              "       'Casual bottoms', nan, 'Chemises'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}